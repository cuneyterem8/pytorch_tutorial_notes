{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch based on official doc Introduction to Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(root=\"data\", train=True, \n",
    "    download=True, transform=ToTensor(), )\n",
    "\n",
    "test_data = datasets.FashionMNIST(root=\"data\", train=False,\n",
    "    download=True, transform=ToTensor(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU(), nn.Linear(512, 10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y), in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch%100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.312259  [    0/60000]\n",
      "loss: 2.296057  [ 6400/60000]\n",
      "loss: 2.275776  [12800/60000]\n",
      "loss: 2.269691  [19200/60000]\n",
      "loss: 2.254359  [25600/60000]\n",
      "loss: 2.219709  [32000/60000]\n",
      "loss: 2.235388  [38400/60000]\n",
      "loss: 2.191299  [44800/60000]\n",
      "loss: 2.194493  [51200/60000]\n",
      "loss: 2.163822  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 2.156424 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.170651  [    0/60000]\n",
      "loss: 2.159404  [ 6400/60000]\n",
      "loss: 2.097608  [12800/60000]\n",
      "loss: 2.119868  [19200/60000]\n",
      "loss: 2.065700  [25600/60000]\n",
      "loss: 1.996933  [32000/60000]\n",
      "loss: 2.041130  [38400/60000]\n",
      "loss: 1.943093  [44800/60000]\n",
      "loss: 1.959476  [51200/60000]\n",
      "loss: 1.892565  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 1.884977 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.918921  [    0/60000]\n",
      "loss: 1.891506  [ 6400/60000]\n",
      "loss: 1.765785  [12800/60000]\n",
      "loss: 1.820157  [19200/60000]\n",
      "loss: 1.703855  [25600/60000]\n",
      "loss: 1.639918  [32000/60000]\n",
      "loss: 1.687607  [38400/60000]\n",
      "loss: 1.561984  [44800/60000]\n",
      "loss: 1.601703  [51200/60000]\n",
      "loss: 1.504459  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.2%, Avg loss: 1.515177 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.581398  [    0/60000]\n",
      "loss: 1.552254  [ 6400/60000]\n",
      "loss: 1.391596  [12800/60000]\n",
      "loss: 1.476820  [19200/60000]\n",
      "loss: 1.356819  [25600/60000]\n",
      "loss: 1.337353  [32000/60000]\n",
      "loss: 1.373264  [38400/60000]\n",
      "loss: 1.274634  [44800/60000]\n",
      "loss: 1.320040  [51200/60000]\n",
      "loss: 1.228799  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.248127 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.325410  [    0/60000]\n",
      "loss: 1.312189  [ 6400/60000]\n",
      "loss: 1.137342  [12800/60000]\n",
      "loss: 1.251110  [19200/60000]\n",
      "loss: 1.131096  [25600/60000]\n",
      "loss: 1.142262  [32000/60000]\n",
      "loss: 1.180318  [38400/60000]\n",
      "loss: 1.097162  [44800/60000]\n",
      "loss: 1.143991  [51200/60000]\n",
      "loss: 1.067399  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 1.082430 \n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to model1.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model1.pth\")\n",
    "print(\"saved to model1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\",\n",
    "    \"Bag\", \"Ankle boot\", ]\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "x_np = torch.from_numpy(np.array(data))\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.3364, 0.7048],\n",
      "        [0.5028, 0.5957]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.8730, 0.5158, 0.4791],\n",
      "        [0.6362, 0.6918, 0.8956]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:  tensor([1, 2, 3])\n",
      "First column:  tensor([1, 4, 7])\n",
      "Last column: tensor([3, 6, 9])\n",
      "tensor([[1, 0, 3],\n",
      "        [4, 0, 6],\n",
      "        [7, 0, 9]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2, 3],[4, 5, 6],[7, 8, 9]])\n",
    "print('First row: ', tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[..., -1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 3, 1, 0, 3, 1, 0, 3],\n",
      "        [4, 0, 6, 4, 0, 6, 4, 0, 6],\n",
      "        [7, 0, 9, 7, 0, 9, 7, 0, 9]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10,  22,  34],\n",
      "        [ 22,  52,  82],\n",
      "        [ 34,  82, 130]]) \n",
      "\n",
      " tensor([[ 10,  22,  34],\n",
      "        [ 22,  52,  82],\n",
      "        [ 34,  82, 130]])\n",
      "tensor([[ 10,  22,  34],\n",
      "        [ 22,  52,  82],\n",
      "        [ 34,  82, 130]])\n"
     ]
    }
   ],
   "source": [
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "print(y1, '\\n\\n', y2)\n",
    "\n",
    "\n",
    "y3 = torch.matmul(tensor, tensor.T)\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  0,  9],\n",
      "        [16,  0, 36],\n",
      "        [49,  0, 81]]) \n",
      "\n",
      " tensor([[ 1,  0,  9],\n",
      "        [16,  0, 36],\n",
      "        [49,  0, 81]]) \n",
      "\n",
      " tensor([[ 1,  0,  9],\n",
      "        [16,  0, 36],\n",
      "        [49,  0, 81]])\n"
     ]
    }
   ],
   "source": [
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.mul(tensor, tensor)\n",
    "\n",
    "print(z1, '\\n\\n', z2, '\\n\\n', z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(30)\n",
      "30 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "print(agg)\n",
    "\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 3],\n",
      "        [4, 0, 6],\n",
      "        [7, 0, 9]]) \n",
      "\n",
      "tensor([[ 6,  5,  8],\n",
      "        [ 9,  5, 11],\n",
      "        [12,  5, 14]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAHRCAYAAAABukKHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZxdVZX3/+9iCgmZJyAzM4Qw2cSoBBAaEIQIaD8yiqDgIziBqI/d2IoMagvdDjSKjYqACIIDKjTtyCBhCCCzEAghE5kTMg8ksH9/3Jtf11l7naqTm0pVperzfr3ygr1r3XPPrdp1dt271tnbUkoCAAC5rdr7BAAA6KiYJAEAKMEkCQBACSZJAABKMEkCAFCCSRIAgBJMkkA7MLOzzezBZr5+j5l9uC3PCV2Xmf3UzC4t+drWZrbCzEa08Wl1CF1ykjSzaWa2uv6Df93M7jaz4e19Xuh8zGy8mT1kZkvNbLGZTTSzsS09LqV0XErpxmaO2+wki86tfu3a8O+tJtezFWZ2RsljPmZmk81suZnNNbO7zGyHlp4rpfRmSqlnSmlGM+dTOslu6brkJFk3IaXUU9LOkuZJuqadzwedjJn1lnSXamOrv6Shkr4qae0mHnebTT87bMnqk1bP+jVshurXs/q/W3y8mf2jamPvgymlXpL2lfSL1jgXM9u6NY7TUXXlSVKSlFJao9pgGS1JZna8mT1pZsvMbKb/68jMzjKz6Wa2yMz+tf6u9Kh2OHV0fHtKUkrp1vpf46tTSn9IKT2zIcDMrq5/mvGqmR3XpP8+Mzu3/v9n19+BfsvMFkv6uaTrJL2z/s5hSRu/Lmx5xkqamFJ6WpJSSotSSj9JKa1sEtO//jH/cjN72Mx2kWp/lJlZMrNR9fZPzexaM/sfM1sp6f9KOkXSv9TH46/b9JVtZl1+kjSzHqr9gB+pd62UdJakvpKOl3S+mZ1Ujx0t6XuSzlDtHWgf1d4dAJGXJL1pZjea2XFm1s99fZykyZIGSvqmpB+ZmZUca5ykqZIGSzpT0sclPVx/59B385w+OpFHJB1vZl8xs3eZWbcg5nRJ/6rapx4zJF3ezPFOV+2daS9JP1LtD7ev1cfjya176u2rK0+Sd9b/Al8m6WhJV0lSSum+lNKzKaW36n/x3yrp8Ppj/knS71JKD6aU3pD0ZUksfotQSmmZpPGqjZHrJS0ws9+a2Y71kOkppetTSm9KulG1P7x2jI+m2Smla1JK61NKqzf7yaNTSSndp9r1a6ykeyQtNLOrzKzpHPCLlNLjKaV1km6RdGAzh/x1Sunh+nVyk9IHHV1XniRPqv8F3k3SJyXdb2Y7mdk4M7vXzBaY2VLV/mIfWH/MEEkzNxwgpbRK0qK2PnFsOVJKL6SUzk4pDZM0RrUx9O36l+c2iVtV/9+eJYeaWdIPFDSpRt3wb4gkpZTuTimdIKmfpPdLOk/SOU0eOrfJ/69S+ViUutB47MqTpKT/v3LrV5LeVO2v/p9J+q2k4SmlPqrlfjZ8BDZH0rANjzWz7pIGtO0ZY0uVUnpR0k9Umyw3+uEttAFJhWrUDf9mu6+/lVL6o6T71NhYlLrQeOzyk6TVnKjaX1cvqPYZ++KU0hoze7tqn71v8AtJE+qf6W+n2mfyZTkkdHFmtreZXWxmw+rt4ZJO0//mvzfFPEnD6uMQaJaZnWxmHzSzfvVr3jskHarWGYtSbTzu2krH6lC68iT5OzNboVpO8kpJH04pPS/pAkmXmdly1XKOt294QP3rn5J0m2rvKpdLmq9NLOlHp7VctYKbR+tVgI9Iek7Sxa1w7L9Iel7SXDNb2ArHQ+e2RLXU0RTVrnk3qlZo8/NWOv4PJR1Qr9RulVtLOgpj0+XGmVlP1QbfHimlV9v7fAAArasrv5NsiJlNMLMe9ZUqrpb0rKRp7XtWAIDNgUly450oaXb93x6STk28HQeATomPWwEAKME7SQAASjBJAgBQotndBMyMz2K7sJRSu9wD2lnG3THHHJP1PfHEE4X2okWNLdg0fvz4rG/BggWF9uTJkxs6drR8bFumZdpj3HWWMXfAAQdkfYcddlih/frrr2cxS5bka+QPH17cPXDMmHzdgeuvv77QfuqppyqdZxXlyxj/r9Yal82NOd5JAgBQgkkSAIASTJIAAJRgkgQAoESz90l2lmQ2GtMVCncaLVL51Kc+lfWNGjWq0D7yyCOzmBkzZhTa69evz2KivjfeeKPQPumkk7KYu+66q8XjTJ06tdC++uqrs5jly5dnfVttVfx7+q233spiWguFOzXbbrttof2ud70rixk8eHChvWzZsiyme/fuhbYfp5I0bNiwrG/+/PmF9muvvZbFLFxYXDZ4yJAhWcxjjz1WaD/33HNZTHujcAcAgAYwSQIAUIJJEgCAEuQkUaor5CSr+sEPflBof/CDH8xifv7z4tZ8ffr0yWIOOeSQQnvNmjVZzJtvvpn19ezZs9B++eWXs5j77ruv0P7ABz6QxQwcOLDQ/tznPpfF3HrrrVnfdtsV93b2OdLW1Nlykj169Ci0d9lllywmygkOGjSo0I4WnvB5w0i3bt0KbZ+jlOI8tLd2bcvb5u60005Zn89n+++HJK1cuTLre/755wvt6LVWOacqyEkCANAAJkkAAEowSQIAUIJJEgCAEs3uAgKgxhe4zZkzJ4vxOzDceOONWcyTTz5ZaO+1115ZjL+JXJL+/ve/F9qvvvpqFvP5z3++0F63bl0Ws3Tp0kI7uvk8Ei1M0Nn5hSaqLDKx9dZbZ31+N5joexntwuGLaaIiFV+U44tkpHzhh+g4VR7Xq1evLMaLiov8691+++2zmG22yaei973vfYX2008/ncU8+OCDLZ7TpuKdJAAAJZgkAQAowSQJAEAJcpJABf4G6GhhdH/D/WWXXZbFPPzww4X2Sy+9VOn5x44dW2h/4hOfyGL8wgSLFy/OYnw+aMSIEZWevytqZNf7cePGtRgT/cyjPHSUu/N8fjFaiMK/jkYX9Y8Wtfe5zOg4Pt9YdVH/iRMnFtr77rtvFuMXS49yu5uKd5IAAJRgkgQAoASTJAAAJZgkAQAoQeEOUIFfKCAqUPBFDNFO7gcddFCh/fa3vz2LiW5I90U5r7/+ehbjFw+ICjR88YXf2R4bx/+sohvu/c+qb9++WYwv+pLyYpZoxxj//NFN+b5v9erVWUxUOOTPKSqu8bvBRGPX/15EBUDR71O/fv0K7WinkD333LPQnjRpUhazqXgnCQBACSZJAABKMEkCAFCCnCRQgc+H9OnTJ4vxuZYoP7Nw4cIWnyvKz/j8YrQgtX++KjeN77333i2ejxTnkZDnzbp3757F+IXKo/zjihUrsj7/84wWF/A/l+jn5HOJO+ywQ4sxkrRq1apmzyfqixYz8PnOaOxGi/H7hRKi17bLLrsU2uQkAQBoQ0ySAACUYJIEAKAEkyQAACU6dOHOgQcemPXttttuhXa0i8H+++9faI8cOTKL6dmzZ6Ed3WBbpVghKo7wyesoKe1FO81HuwU8//zzhbbfsV6SZs2a1eLzoVx0g/2gQYMK7ajQwhcoVNkRIRo/ET8Wq+zaEBVa+LHof1ewcfy1Jbrhv1u3bi0eJyrK8WMluh75vqgoyBfK+EIiKR6H/vmjgpsq18gq5xgVDvmFGfr375/F+Ou2v65L8e/qxuCdJAAAJZgkAQAowSQJAEAJJkkAAEq0W+GOX6nioYceymKqrAYSFTAsWbKk0I4S1V6UlK76fJ5PVEfH7tGjR6F92GGHZTHR6h1V+HM89NBDs5iJEycW2lGRR1f1sY99LOvz358q4yAqhqhaqNPS4xo9ti8siQodxo0bl/U9+uijLR67K/K/o9GKM75Qxf/uS/E1yq+ME+2CUWXFHd8X7fhR5fpXpXCnyi4g0Q42fj6Q8h1zoiJF/z2KrpkU7gAAsJkwSQIAUIJJEgCAEtZcbsXMWk68VBB9Tj1t2rRC2+9wLUkzZ87M+gYMGFBoRzfv+hxAdKNu9Dgv+gze9zWaG/I3z1ZZcEDKP3OPnmvUqFGF9hNPPJHFHHLIIS0+V0qpsQTaJmqtcdeoKVOmZH1+fEbjtcrY8KrkNiNVcshVdoSIdjOZOnVq1nfUUUdtxNltmvYYd1XGXPTzPPbYYwvtaFz47/mYMWOymD//+c8tnuOOO+6Y9fmb6f0CAFVVyTdWGU8RvyhA9FxnnHFG1vfaa68V2i+++GIW4/Orjz/+eBbz3HPPtXiOzY053kkCAFCCSRIAgBJMkgAAlGCSBACgRJssJrDvvvtmfb5QZcaMGVlMdBPo8OHDC+3oxlifPI92+PA3UUeFM1GiuspNt1Vu/PY7A0Qr40d9XnSO/nu5zz77ZDHjx48vtB988MEWn6uriIppopvE25I/p9Yam9G4b7T4o7MbOHBg1ldlhwt/jYoWSYkKV0455ZRCOyqy8j+rKj+7qNimSpFiFdH12Bfu+MVeJGno0KFZny/UiYqiFi1aVGj37du30nluDN5JAgBQgkkSAIASTJIAAJTY5ORDlZtQo8+S/WfXUY7Ff5YtSY899lih3bt37yzGL5a7bNmyLMbnDqLP0qPP7n1Op8oNttHO5FV2ml+7dm3W588zyoH473d0jl/+8pcL7WOOOSaL6aqivMacOXPa4Uxanx+/0e9mtPgGpBEjRmR9flGS/v37ZzG+JiK6rowdO7bF5x88eHDWN3fu3EI7WuDb//6vWrUqi6myMHl0rffjKbpm+/N++eWXs5joGu0XL4+udf4aOWjQoCxmU/FOEgCAEkySAACUYJIEAKAEkyQAACXa5K7hnXfeOesbNmxYof3UU09lMdFOHb7QIFpwwN+YGt0w7YtpomR6VEzjk9dRUY4/xygp7p/PJ6mlOFHtd/WOztsX90TFGX5RhvPPPz+L6aqiG7J98UNr7eQeLTRRZWeQaExVWfDAP190jo3uTNLZRUUx/vsX/c726NGj0I4K8v70pz9lfSNHjiy0q/zMo7Hrf/+jIsUqYzXin2/lypUtnuMuu+ySxfjXKuXX1meeeSaL8QssRN9/vwjEwoULs5jm8E4SAIASTJIAAJRgkgQAoMQm5ySrfG4d7cTtPxfeaaedsphooQAvyrf5G1Ojm6N9Ls/nDaIYKf98Pcrf+NxFdJwqi/5G+U6/oG90g7HPeQwYMCCLueeeewrt73//+1nM9773vayvK2h0ge8qC010NFFONMp9Ia4b8L/bUd7S58T22GOPLObyyy/P+ny+LbrWNLLwQ9WFy31cNJ79643y4v7aFn0fo5qU97///YX2zTffnMX454uumX4eIScJAEArYZIEAKAEkyQAACWYJAEAKNFshUKjNzp7EyZMyPp8Mnv+/PlZTJRg9ivqRwsORMlzz6+eHyWTowIGX9QRJbN94UzPnj2zGF9cFN1gHPFFONHPw7+2vfbaK4uJfraoiQp3/Pc5+r635fe00Rv+q7yOzbG7+5bIF/NF15WlS5cW2tH1wF/b9t133ywm2j3EF5jsuuuuWYy/eT66ZlYpRKuyEEV0bP+4KgsuRAsOfPazn836zjvvvEL7tNNOy2Kuv/76Fo/t55qpU6dmMc3hnSQAACWYJAEAKMEkCQBACSZJAABKNJvRba3dAFatWtViTLSbR1RAEBXYeH4VjCiZ61f4iVbuiVZm8EU40QoPvoDDJ/ej40Qr80cJd/+9jFbT8T+3xYsXZzF+5Z6uyq9qIsXFF774ICpi8IVeVYp7ooKJqACotYqCqqwKFI3FrsivZhUV4M2ePbvQ7tevXxYzatSoQjv6nr/00ktZn7/+tdbPKlqlp8rqUNGY9+MpKnasUrgTXf///ve/F9ojRozIYnbfffcWjzN69OhCe9KkSVlMc3gnCQBACSZJAABKMEkCAFCi2ZxklBPz+T7/mbAkfeUrXym0582bl8UsX7680I5yQ1FOx38GH+Xk5syZU2hHu1X7z8WjXEJ0g79//ujmWZ+7iD6D9/mOKnmw6PmjnITf+Ts6zsbeUNtZRWOjtbTm4gL+Zxgdu8ruDlVyT1XGdJT76Wx8/cOCBQtafMzOO++c9fldkKLrSpST9I9bt25dFlPlZ+6v49HYicaF74vmA1+TEeXYfQ7U53HLvPLKK4X2nnvumcXst99+hfa1116bxcycObPS85XhnSQAACWYJAEAKMEkCQBACSZJAABKNFu444t0IhMnTsz6/I35UcLX3+AeLTgQLRzgH1fl5tXodfjkebSYQLRQgH++6Pl9gj16/f5m/ijhXeW1RfxriYp7nnzyyRaP0xVEP5voe9zIwhqN7hRS5abtiI+Jnt8fOyrY8LtfSPnvYlco3PE79fz+979v8TFRAeK4ceMK7ccee6zS8w8bNqxSXGuocl2Jrkd+/FTZTWT48OFZX3SDf1TM5F1yySWFdrRwSnQd3xi8kwQAoASTJAAAJZgkAQAo0WxOMsqD+M98o0XAfb4tWnDA35w8cuTI5k6l9PmjvEv02bnnX1v0WqNcpj92lcdF59Nobsr3RTcm+13Oo3zvlClTWnz+riDKv0Wq/Lz8WGx0ofLWelyUb/TnGP3+RDkcn2uLFgjpbPyiCv73SsoXRXn55ZezmFdffbXQrrrAtr8mVskxV7lmVbk+RseO8vdetHi6X0xl/PjxWcy9996b9fkccLQoi19MJnp+r8qGG03xThIAgBJMkgAAlGCSBACgBJMkAAAlms3E+hXWpTwxHN086xP/UcL5xz/+caE9bdq0LGbgwIFZny9U8bt3S/nN81HC2cdEN8FGfX7XiKi4xj8u2mnC3/AfJZOjBQ58YjraBcV/v2+88cYsJiq46op69eqV9UUFL621o0ejhTtVFgGoUozmx0Z0nOj3JSpa6eyq7BDji3uiwpElS5YU2vPnz6/0/P7YS5curfS4lkSFO1UWAYjGhT+Wf61SvuNRtEjA2LFjsz5/jdp1111bPMfomjlo0KBCe2N3BeGdJAAAJZgkAQAowSQJAECJZnOSzzzzTNbnPyceNWpUFuMXQ47yHp/5zGeqnB+wWfl8SVVVFiFvdMGIKlort1lVv379Gnrclszn+6O6Ab+YQFRH4XNifgMEKV7UwucA/QIsUl6jUSUPHYnyr77+JMpbVlk83L+2yZMnZzFHH3101vfHP/6x0B4xYkQW4+eW6HW88sorLZ5jc3gnCQBACSZJAABKMEkCAFCCSRIAgBItL+vuTJgwodC+7LLLshifcL3hhhtaPG5UUBAV/GDjNZrM7wqq7gLiNVo4UyWmtRYTiH7GPqbKTeRS49+nLdn999/fYoz/fu64445ZzBNPPFFo33PPPVnMCSeckPX53ZR69+7d4vNXWQAhGhdVxlOV3UOi6/iKFSsK7WjBhWgXqOHDhxfap556ahYzZ86cFs9pU/FOEgCAEkySAACUYJIEAKAEkyQAACU2unBnypQphfbpp5/eKidCkc7mQ5FOOb8bjFRtLFYpuImKGPzPIoqJCiSqFE20dD7R81cV7a6A/Pv53HPPZTFRn+dX5ZGkNWvWFNpRwYsfP1V26vCr9EjxmPe/G9EYjJ7Pe/311wvtaFxOnz496/OvrS2KdCK8kwQAoASTJAAAJZgkAQAosdE5SaAz6d+/f6U4n3uK8jNV8n2NLjBQ5dhVdviocpxogYFGcqKIde/ePevr27dv1jd79uwWj+V/5tHPyY+nKP9YZVebKjHRggcrV64stKMFD1577bWsr8qY8zFVF8fYGLyTBACgBJMkAAAlmCQBACjBJAkAQAkKd9ClDR48OOtbsGBB1ueLFqrssBHxj6taROELFBpdfMM/f1REERWMDBw4sKHn62qqFF0NHTo0i+nWrVvW52/mj2KqjDk/VhpdUCIal+vWrWu2LcWLF3hRkc7YsWML7e9///stHmdz4J0kAAAlmCQBACjBJAkAQAlykujS9t1330pxfiHnRhcFqHKDdpUbwqvEVHn+aIH36NgHHHBA1ofG9OzZM+uLcsz+JvwBAwZkMT6nHC1Ev379+kI7WsygkXy6lOdJo/HkX8fq1auzmPnz52d9Ue7W878/LCYAAEAbYpIEAKAEkyQAACWYJAEAKEHhDrq0Xr16ZX2+0EDKCyuiHdn33nvvFp+vSmFBdGxfWBEVUVQ59osvvlhoR4UeK1asyPqWLFnS4rERF2L5n0uPHj2ymGixhrlz5xbaUVGMH5eN3szfWqICIP89iV6HXzhAkv7pn/6p0L7ooouymOj1tjbeSQIAUIJJEgCAEkySAACUsOYWuzWzxlbCRaeQUmr5DuPNgHHXtbXHuGutMVdlgfMoJsrJHXTQQYV2nz59shifk/QLB0h5TrR3795ZTKRKjts/f5RvXLhwYaE9Y8aMLCbK0+6www6F9k033dTi+TSquTHHO0kAAEowSQIAUIJJEgCAEkySAACUaLZwBwCArox3kgAAlGCSBACgBJMkAAAlmCQBACjBJAkAQAkmSQAASjBJAgBQgkkSAIASTJIAAJRgkmyQmSUz271C3Kh67DZtcV7ovMxsmpkd1d7nAXQlnW6SNLPxZvaQmS01s8VmNtHM8s3agE3AOMOWoP6H1WozW2Fmr5vZ3WY2vL3Pa0vSqSZJM+st6S5J10jqL2mopK9KWtue54XOZUsfZ3yq0eVMSCn1lLSzpHmqjVtU1KkmSUl7SlJK6daU0psppdUppT+klJ4xs93M7C9mtsjMFprZLWbWd8MD639xfc7Mnqm/O/i5mW3f5OufN7M5ZjbbzD7S9EnN7Hgze9LMlpnZTDO7tM1eMdpDc+PsbDN70Myurv/l/qqZHbfhgWbWx8x+VB9Lr5nZFWa2df1rzY7Rpsxs7/qxT623h5jZL81sQb3/001iLzWzX5jZT81smaSzN+c3Bx1TSmmNpF9IGi21fN0ys7PMbHp9PP5rV/24v7NNki9JetPMbjSz48ysX5OvmaSvSxoiaR9JwyVd6h7/QUnHStpF0v6qX0zM7FhJn5N0tKQ9JPmBslLSWZL6Sjpe0vlmdlKrvSp0NM2NM0kaJ2mypIGSvinpR2Zm9a/dKGm9pN0lHSTpGEnn1r9WZYzKzN4m6Q+SPpVSus3MtpL0O0lPq/au9h8lXWhm72nysBNVu0D2lXRL4y8dWyoz6yHpFEmP1LtKr1tmNlrS9ySdodo70D6qja2uJ6XUqf6pdnH5iaRZql2MfitpxyDuJElPNmlPk3Rmk/Y3JV1X//8fS/pGk6/tKSlJ2r3kHL4t6Vv1/x9Vj92mvb83/Nv840y1P6ymNInrUf/571T/+lpJ3Zt8/TRJ95Y8RzRGv1p/ziOa9I+TNMM99p8l3VD//0slPdDe3zP+tf2/+phZIWlJfZzOlrRfSWzT69aXJd3a5Gs9JL0h6aj2fk1t/a/T5SZSSi/of98B7i3pp5K+bWafkfRdSYdK6qXau+jX3cPnNvn/Var9Ra/6f59o8rXpTR9kZuMkfUPSGEnbSeom6Y5NfzXoqMrGmaTfq8k4Simtqr+J7Kla/nJbSXP+942ltpI0s36cwWp5jH5c0v0ppXub9I2UNMTMljTp21rSX5u0Zzb2StEJnJRS+lP9Y/0TJd1ff6c4UuXXrSFqMmbq43hR2552x9DZPm4tSCm9qNpf+2NU+xgrSdo/pdRb0pmqfbxVxRzVPvraYIT7+s9UeycxPKXUR9J1G3FsbOHcOGvOTNXeSQ5MKfWt/+udUtq3/vUqY/TjkkaY2bfccV9tcsy+KaVeKaX3Nj3Nxl4dOotUy5//StKbksar+evWHEnDNjzWzLpLGtC2Z9wxdKpJsl7McLGZDau3h6v2cdYjqv1lvkLSEjMbKunzG3Ho2yWdbWaj65/rf8V9vZekxSmlNWb2dkmnb+prQcfVwjgrlVKao1ou8d/NrLeZbVUv1jm8HlJljC5XLW9+mJl9o943SdIyM/t/ZtbdzLY2szHckoKmrOZESf0kvaDmr1u/kDTBzN5lZtup9jF/l/zDv1NNkqpdQMZJetTMVqp20XpO0sWq/ZDfJmmppLsl/arqQVNK96j2UdpfJE2p/7epCyRdZmbLVfss//ZNexno4JobZy05S7WPtv6u2kepv1CtMEKqOEZTSktUKyI7zswuTym9KWmCpAMlvSppoaQfqlZsAfzOzFZIWibpSkkfTik9r2auW/Wvf0rSbaq9q1wuab62kNucWpPVk7IAAITMrKdqxT97pJRebe/zaUud7Z0kAKAVmNkEM+thZjtIulrSs6pVy3YpTJIAgMiJqt0yMlu1+8NPTV3wo0c+bgUAoATvJAEAKNHsYgJmxtvMLiyl1C4l34y7rq09xl1XGnPXXJOvbz579uys7+tf/3qLx2qyKIYkaUv9ZLK5Mcc7SQAASjBJAgBQgkkSAIASTJIAAJRo9haQrpTMRo7CHbQHCneq6969e6G9evXqLOZb3/pWof3b3/42i4nmgR122KHQvvvuu7OYbbYp1n6uX7++/GQ7MAp3AABoAJMkAAAlmCQBACjR7GICAICOK8pBelttVXwvNGnSpCxm5cqVWd/NN99caEc5SZ+D9IsLSFvuAgMb8E4SAIASTJIAAJRgkgQAoASTJAAAJSjcAYAtwHbbbZf1vfHGG4X2uHHjspg+ffoU2lGRTmTXXXcttA888MAs5qmnniq0/eICkrRu3bpKz9dR8U4SAIASTJIAAJRgkgQAoAQ5SQDYAlTJ7R177LFZ34svvtjQ8913332F9t57753F+JykX7igM+h8rwgAgFbCJAkAQAkmSQAASjBJAgBQgsIdANgCVNlN4+CDD876Lrzwwoae7/bbby+0TzvttCzmtttuK7T9riCdAe8kAQAowSQJAEAJJkkAAEqQkwSADsjMCu0oJ/mOd7yj0I4WQX/llVcaev6nn3660D733HOzGP98fsF1KV9g4K233mrofNoL7yQBACjBJAkAQAkmSQAASjBJAgBQgsIdoAHRbge+IMEXXkjVbgiPfPjDHy603/a2t2Uxn/nMZzb6uFVeRxQXPc7fSL799ttnMWvWrNnYU0Qz/K4fU6ZMaeg4W2+9ddb35ptvFtpz587NYiZMmFBo//KXv8xitt1220J77dq1jZxiu+GdJAAAJZgkAQAowQViBXIAACAASURBVCQJAEAJJkkAAEpQuANU4ItwqqwaUqVwZ/jw4VnMFVdckfX5wp2LLrooi7nkkksK7SuvvLLFc6y6+ol/LdFuD927dy+0V69evdHH7aoaLfI65JBDCu3rrruuxcdss01jl/2//e1vWd8RRxxRaEeFO1taoY7HO0kAAEowSQIAUIJJEgCAEtbc595m1tidz+gUUkrtkjDaEsZdlEPyuZ5169a1eJybbrop63v3u9+d9f3mN78ptHfdddcsxt9YHt0g7kUxUZ7SXyeixQTOP//8Qvu1117LYu68884Wz6k9xl005qosoOD7olytF31/ozyhP9b++++fxfzXf/1Xoe13BYlUzQNXyYkuXbq00B44cGAW438Pou9jleeKHldlpxT//Y5imhtzvJMEAKAEkyQAACWYJAEAKMEkCQBACRYTABoQJf+rFOp8/OMfL7T9DfiS9Mc//jHr69u3b6H90ksvZTEzZswotI877rgs5p577im0/U4PVd14441Znz/WmDFjspgqhTsdhS/4qLrwQiOqFPx86EMfyvpWrVq10c/V6E40kYceeqjQjnaiufrqqwvtRr+PjY7VTcU7SQAASjBJAgBQgkkSAIAS5CTbSZWbYFuLX4RYyheffuSRRzbb87cVf0N2yU3DhXaj+ZHoxmZ/I7dffFqS3vnOd7Z4nB122CHr8/mY6Mby7bbbrtnzkaTDDjus0L7llluymMmTJ2d973vf+wrtKJc6f/78QrtPnz5ZzJYsulF+1KhRhfbs2bOzmL322qvQjnLXxxxzTNb36quvFtrRAhKTJk0qtKMF8/2xn3/++Sxm5513zvr222+/Qvu///u/sxh/LD++pDwnGeWqFyxYkPXNmzcv6/NGjhxZaE+fPr3Fx2ws3kkCAFCCSRIAgBJMkgAAlGCSBACgRJvsAtLortuRcePGFdonnnhiFuN30PbJdSlPCt9xxx1ZzJo1axo4w9az7bbbZn0XXHBBoT106NAsxu++MGXKlCzm4YcfLrQXL16cxXSkXUDastDJF8BI0ic+8YlCe8cdd8xi3va2txXaS5YsyWJ8cVH0uxHt5O6LeRYuXJjF9OrVq9COxoZ/bb7YpuzYfreQWbNmZTH+tUW/d5dddlmh/dRTT2UxHWUXkDPOOKPQ9sVLkjR48OBCe9q0aVnMBz7wgUI7Km6Jjn3wwQcX2nPmzMliDj/88ELbX/sk6dBDDy20zzvvvCzmf/7nf7I+P36jseKvG8uXL89i/OMOOuigLObyyy/P+n72s58V2t/4xjeymAMOOKDQ3m233bKYj33sY4X2/fffn8WwCwgAAA1gkgQAoASTJAAAJdokJ1nFF77whazvL3/5S9Z38803F9o//elPs5grr7yy0O7Ro0cWM2TIkEJ77NixWUy0Q/yiRYsK7bvvvjuLmThxYtbn+cWKfa5Rim8Gf+KJJwrtaMHoK664osXnr6Ij5SQbEd3w7m/sPvXUU7MYn9uTpJ122qnQjhYB8Dk5ny+SpOeee67Qjn7uu+yyS9bnbywfMWJEFnPhhRcW2itXrsxifM4ourE9yk/7xSd8vkySnn322UI7ukH95z//eaH9m9/8JovpKDlJf6O6z6dK0vbbb19oR3UEL7zwQqEdveaZM2dmfddcc02hHeXBff44yqe/8cYbzbYl6fbbb8/6evfuXWgfffTRWYx//dF11C9UEi1csu+++2Z9gwYNKrQfeOCBLMYv4j9s2LAsZvz48YV2lFslJwkAQAOYJAEAKMEkCQBACSZJAABKNLsLSFSc0MhN3NFjvvjFLxbaPkkrSc8880zW953vfKfQ9jfKStJHP/rRQvtHP/pRFuNvsI9uuL/11luzPn/z6kknnZTF+AS3T4BLeQHJueeem8VEq/V3Vb6I6brrrsti/C7tUQGO303DF6RI0tKlS7M+X6AQjdeXXnqp0P7rX/+axfjig6iobMCAAVmfLzbwOytI+WvxRTKSdOaZZ2Z9Xrdu3bI+/9quuuqqLMYXw0WFZ0cddVShHRWxdBS+8CkqePGFM9HiEE8//XShHRW3+O+dlBdnReP5xz/+caG99957ZzHeHnvskfVF49DzRYtSvjPKihUrshj/uxI9V3RsvzCAHztSvtNMtJhCVKizMXgnCQBACSZJAABKMEkCAFCCSRIAgBLttuKOT3i/5z3vyWJ8kYWUJ/onTJiQxdx7772FdlQI0ShfwPHJT34yi/nIRz5SaEcFHH6nDl8YIcUFJOvXry+0Z8yYkcX43UuilWf89z9aZeXNN99slxV3vvWtb2Xjzif/o1U7/Ko4focGSRo+fHihHRUR+B0vpHx3B78bjZT/vPw4lPLdPKIVd/wONVK82kpLokKTf/u3fyu0zznnnCwmWrXErwjjv4/RsX/yk59kMbNnzy60ly1blsV0lBV39t9//0L7+uuvzx530003FdrRCmB+JSR/XEl66623sr7jjz++0P7sZz+bxfgCNr9bjZQXUM2dOzeL6du3b9bni2L8a5Wks846q9D2hTxSvhtNtPNLVNzox3y0O41f5Spapa3KCmSsuAMAQAOYJAEAKMEkCQBAiWZzkjvttFP2xd13373QjnZf93mXU045JYs55phjCu0f/vCHWcyxxx6b9fnPqaPV6/1Np6+88koW4xdKiPJX/vPu6PmjRQj8TchRvs+vTD969OgsxucfpXxhhujY0e4Pns/33nDDDVnMf/7nf7ZLTnLs2LHZuPvSl75UaPfv3z973C233FJo+9yslN9MP2rUqCwm+p3wiwBE+XK/u3yU2/Q3+Ec3dkc3RPud26NFELzoe+QXCoh2u69yQ3qVG8KnT5+exRxyyCGFdnTz/V//+tcOkZP0OblZs2Zlj7vvvvsK7Shv5nN5559/fhbjd3mRpMMOO6zQ/o//+I8sxtc7fO5zn8tifL6zX79+WYzPG0p5jvn+++/PYi655JJC2+9yI+W56QcffDCLia61fhxG1/G1a9cW2tHvk1+8Iar1ICcJAEADmCQBACjBJAkAQAkmSQAASjRbuDNmzJjsiyeffHKLB91uu+0KbX/jvJSvzO6LfaR4Zfhtt9220I6KIxYsWFBoRzdV+4RvtONGVDizufhdUaQ4me2/t1VuPI9ehy88iW78njVrVrsU7lRZxCIqLvFjKEri+50VTj311CwmKtDwBWvXXHNNFuNvuO/Zs2cW4wsbonHnx3jUF+2w8S//8i+FdrSLTvTavKjgxo/FqODGL+YQ7XbhC/18cYgkTZs2rUMU7vjXGI0VXxwVLW5y1113FdrRTix+Bxsp/x393ve+l8X8+te/LrSjoiD/exD9XvgdN6R84ZZohw/f53dpkqSbb7650D7wwAOzmOj1X3nllYV2tOPT2972tkLb/w5K0tlnn531eRTuAADQACZJAABKMEkCAFCi3RY4R8fXHgtNS9L222+fjTu/sHyUZ/WLB0SLRvs8U5Rbi34nfFyUC6+iyiIW0YL0/vX7nHp07CjP5Bcv98eV8pvopTyXGOWn/AIHzz77bBbj86TR93H9+vUdIifpVVmY/Ac/+EEW8/TTTxfaUa3FiSeemPW9/PLLhfbUqVOzGL+gejSefL2DPx8p/j3Yc889C22/oEb0fH/4wx+yGP99++pXv5rF/OIXv8j6/OLpUW7Rx0SLMnz0ox/N+jxykgAANIBJEgCAEkySAACUYJIEAKAEhTso1V6FO1XGXa9evbI+f/N+tNt5lQKY6MZmv4hDdGxfxBHtQuLPMSouihYT8IUzUaGFf23R8/tdKqJdZKJz8rt+RN8jL9ptwt98H+2asWTJkg5ZuPP4449nfX4XkKhYyhc0nX766S0eR8oXvoh2hxk3blyh/c1vfjOL+Yd/+IdC2y86IUmzZ8/O+vwiAMcff3wWc8cddxTaJ5xwQhZz5513Ftp+txwpXhzD/x5cfPHFWYwvHFq2bFkWc95552V9HoU7AAA0gEkSAIASTJIAAJQgJ4lS7ZWT3GqrrbJx19w43RjdunUrtKvcuF8/p0LbLz4d8XlMKc8TRseJ8iqNLLY/cODArM/nFiPRc/nv/7p167IY/z2KNhbwudVIe4y7Kte6yy+/POvba6+9Cu2dd945i3n00UcLbZ+jk6QLLrgg6/M380d83i5a+N/nnf3mEpJ03XXXZX1+o4RPfvKTWczrr7/e7PlI+cYD0e/XK6+8kvX5hdCjvOWll15aaEeLEvzwhz/M+jxykgAANIBJEgCAEkySAACUYJIEAKDENi2HAG2rtYp0In7xgGgxgc4iulEfjZs0aVLW96EPfajQ/v3vf5/F/PM//3OhPXny5Cwm2pnDj01fSCNJv/71rwvtAw44IIs599xzC+3rr78+i7nmmmuyPr/AwZw5c7IY78knn8z6vv3tbzd7PpJ0zjnnZH1f+cpXCu1o4YtttilOYT/60Y9aPMeNxTtJAABKMEkCAFCCSRIAgBJMkgAAlGDFHZTqyLuAoPPqqCvujB49Ouv73e9+V2hfdtllWYxf5alPnz6VzunTn/50ob1o0aIsxu8UsnLlyizGr+A0bNiwLOYLX/hC1ud39Ih2+JgyZUqh7VfXkfLXO3369Cwm2lXG7/QT7VRy0003Fdo33HBDFlMFK+4AANAAJkkAAEowSQIAUILFBACggr///e9Z39KlSwvtM888M4uZO3duof2rX/0qizn88MOzvqFDhxba0c4rK1asKLTfeuutLMbnCc3y9Fu0UMGf//znQnuPPfbIYny+Mdr5ZsaMGYV2tBNNtPCF371jt912y2KGDBlSaG+99dZZTJUde5rDO0kAAEowSQIAUIJJEgCAEkySAACUoHAHABr05S9/udA+77zzshh/U3zPnj2zmAsvvDDre/zxxwvts846K4vxCwV84AMfyGIeeOCBQtsXBEn5ogRSvlvHn/70pyzmqquuKrTvvffeLOaSSy4ptKMdT0aOHJn1+YUKoqIgXzi1qUU6Ed5JAgBQgkkSAIASTJIAAJRggXOUYoFztIeOssC5v+m+uWvlBtFCAVVu5v/617+e9b3nPe8ptI8//vgs5oorrii0o8XL3/3udxfa/fv3z2J23XXXrO+3v/1tob3zzjtnMYceemiz5yPlecpLL700i4nytEceeWShffPNN2cx/vkmT56cxWyzTbH0Zv369VkMC5wDANAAJkkAAEowSQIAUIJJEgCAEiwmAACBKoU63kEHHZT1/e1vfyu0Z82alcXcdNNNWd+iRYsK7dWrV2cxu+++e6F95ZVXZjFvvPFGof2ud70ri1m1alXW5xcTmDdvXhYzderUQnv48OFZjH/9jz32WBYzduzYrG/MmDGFtl9cQMoLdbbaKn/fFxXqbAzeSQIAUIJJEgCAEkySAACUYDEBlGIxAbSHjrKYQCOihcrHjx9faEcLfH/wgx/M+nwO0ucopTzfFi1CPmHChEL7z3/+cxbTp0+frO+9731vob127dosxp9TdJw//vGPhXbv3r2zmBdffDHrW7duXaF92223ZTErV67M+hrBYgIAADSASRIAgBJMkgAAlGCSBACgRLOFOwAAdGW8kwQAoASTJAAAJZgkAQAowSQJAEAJJkkAAEowSQIAUIJJEgCAEkySAACUYJIEAKAEkyQAdAJmlsxs9439GprX5SZJMzvdzB43sxVmNsfM7jGz8S0/stlj3mdm57bWOWLLZmbTzGy1mS03syVm9pCZfdzMutzvGzZe/Xryupl16wDncraZvVm/Xq4ws6lmdn4rHfsnZnZFaxxrc+pSv7Rm9llJ35b0NUk7Shoh6XuSTmzP80KnNCGl1EvSSEnfkPT/JP0oCjSzrdvyxNBxmdkoSYdKSpLe164n878eTin1TCn1lPRPkr5pZge190m1lS4zSZpZH0mXSfpESulXKaWVKaV1KaXfpZQ+b2bdzOzbZja7/u/bG/6SM7N+ZnaXmS2o/4V3l5kNq3/tStUG9X/W/9L6z/Z7lehoUkpLU0q/lXSKpA+b2Zj6X9DfN7P/NrOVko6oj7+rzWyGmc0zs+vMrLskmdnA+phbYmaLzeyvG96Vmtn/M7PX6u9aJ5vZP7bjy8WmO0vSI5J+IunDTb9QHzfXmtnd9Z/3o2a2W3QQMxtvZjPN7Ijga6VjrSUppb9JekHSPk2O9z4ze74+Pu8zs6Zf26fet6Qe8756/8cknSHpC/Xr5u+qPH+7SCl1iX+SjpW0XtI2JV+/TLXBOVjSIEkPSbq8/rUBkj4gqYekXpLukHRnk8feJ+nc9n6N/OsY/yRNk3RU0D9D0vmqXQCXSjpEtT9Ut1ftE47fSupfH2O/k/T1+uO+Luk6SdvW/x0qySTtJWmmpCH1uFGSdmvv18+/TRo7UyRdIOkfJK2TtGOTr/1E0mJJb5e0jaRbJN3W5OtJ0u6S3lMfF2/3X6v/f+lYC87nbEkPNmmPlbRE0p719p6SVko6uj42v1B/DdvV21Mk/Uu9faSk5ZL2avJ6rmjv73lL/7rMO0nVJrqFKaX1JV8/Q9JlKaX5KaUFkr4q6UOSlFJalFL6ZUppVUppuaQrJR3eJmeNzmS2ahcmSfpNSmliSuktSWslnSfpopTS4voY+5qkU+ux6yTtLGlkqn368ddUu8q8KambpNFmtm1KaVpK6ZU2fUVoNfXaiJGSbk8pPSHpFUmnu7BfpZQm1a9jt0g60H39/0j6L0nvTSlNCp7D1PxYi7yj/k5whaRJkm6W9HL9a6dIujul9MeU0jpJV0vqLuldkt4hqaekb6SU3kgp/UXSXZJOq/L96Ci60iS5SNJAM9um5OtDJE1v0p5e75OZ9TCzH5jZdDNbJukBSX3JJWEjDVXtnYBU+0t/g0GqfUrxRP1itETS/9T7Jekq1f4i/0O9cOKLkpRSmiLpQkmXSppvZreZ2ZDN/zKwmXxY0h9SSgvr7Z/JfeQqaW6T/1+l2iTU1IWqTbLPljxHS2Mt8khKqW+q5SR3krSvahOr5K6b9T/6Zqo21odImlnv22B6/WtbjK40ST4saY2kk0q+Plu1v+I2GFHvk6SLVftoa1xKqbekw+r9Vv8vO1ejWWY2VrWLw4P1rqZjZqGk1ZL2rV+M+qaU+tQvSkopLU8pXZxS2lXSBEmf3ZB7TCn9LKW04R1IkvRvbfSS0IrqOcEPSjrczOaa2VxJF0k6wMwO2IhD/R9JJ5nZhSVfb3astSSlNE/SL1Ubh5K7btbfqQ6X9Fr9a8NdVfeI+tekLeS62WUmyZTSUklflnStmZ1Uf3e4rZkdZ2bflHSrpC+Z2SAzG1iP/Wn94b1UG1hLzKy/pK+4w8+TtGvbvBJsScyst5mdIOk2ST+N/sKv/6V9vaRvmdng+uOGmtl76v9/gpntXr8ALVPtY9Y3zWwvMzuyXmC2RrUx+mbbvDK0spNU+9mNVu0j1ANVK475q2rFPFXNlvSPkj5tZhf4L7Y01lpiZgMknSzp+XrX7ZKON7N/NLNtVXtDsVa1mo5HVctXfqF+rX23apPrbfXHbhnXzfZOirb1P9Vyj4+r9sObK+lu1T4/317SdyXNqf/7rqTt648ZolpxzgpJL0n6v6r9FbRN/evvrPe/Lum77f0a+dfuY2yaahPWctUKdB6W9AlJW9e//hO5goX6+PuapKmqTYQvSPp0/WsX1Y+5UtIsSf9a799ftRzRctU+xr1L9SIe/m1Z/1T7yPPfg/4P1q9T2/hxI+ndkmY1aTctztlFtY82zw2+VjrWguc/W7XJe0X933zV3lAMbhJzsqS/18f6/aq9S93wtX3rfUvrMSc3+doekp5SrRDozqrfq7b+Z/WTBQAATpf5uBUAgI3FJAkAQAkmSQAASjBJAgBQgkkSAIASZavPSKrtQdZWJ1Ly/Fkf1bhtJ6WU/wDaQHuPuyqisfnrX/+60B45cmQWc+211xbat912Wxazdu3arO+AA4r3k5988slZzAknnFBoP/DAA1nMpz71qayvo2mPcbcljDlsPs2NOd5JAgBQgkkSAIASTJIAAJRgkgQAoESzy9K1dzK70cKdbbYp1iN985vfzGLe857ier7dunXLYqICijffLK4fPXv27Czm2WeLa1h/7Wtfy2Jef/31rK+joXCn3KhRo7K+l156qdBetWpVFrP99tsX2tG4q2LFihVZ37bbbltoT58+PYvZa6+9Gnq+tkThDtoahTsAADSASRIAgBJMkgAAlOjQOcnu3btnfatXry603/GOd2Qxd9xxR4vHeeutt5ptl/X5fGeUU/K51CVLlmQxo0ePLrSjHNPWW2+d9fmc6OZETnLj+JzkwIEDsxg/frfaKv87Nfq5r1+/vtCOxkGfPn0K7UmTJmUxRx11VNbX0ZCTRFsjJwkAQAOYJAEAKMEkCQBACSZJAABKNLsLSHtbt25dizH7779/1tezZ89Ce968eVlMr169Cu2oSCcqqvALDKxZs6bFcxw0aFDW95GPfKTQ/u53v5vFsOPJlsUvFOBv7pfy8RMtmBEV5fhinmhs+OfbYYcdyk8WQCW8kwQAoASTJAAAJZgkAQAo0aFzkv4G6ojP7UnS8uXLC+0o7+OPHT3Xdtttl/X5fFG0CLp/vmgx84MPPjjr86I8KTquF198sdA+4ogjshg/NqMxFv3c/ZiqstDFU089VX6yACrhnSQAACWYJAEAKMEkCQBACSZJAABKdOjCnSrGjRuX9U2dOrXQrrJQQHQD95w5c7I+v1CBL5aQ8uIMf5O5JL3zne/M+rBlW7RoUaEdjQ3fFy0KEC1i4Qt3ohh/7Geeeab8ZNEpRUWKrbUoSXRsv8hFlWLLqsf2510lJrrWnnLKKYX2jTfeuFHnxjtJAABKMEkCAFCCSRIAgBIdOid52WWXZX3nnHNOoT179uwspnv37oV2tFC6v8E/2g0+WqDafwYe5TKrLCztj/PDH/4wi7niiiuyvmnTprV4bLSPKVOmtBhTJbdY5XFRfsabO3dupWOj89icmyJEx66Sg/RjvEpuMzp2lcVVDjvssKzv9NNPL7TvueeeFo/TFO8kAQAowSQJAEAJJkkAAEowSQIAUKLDFO6cdtppWd/555+f9fkb9VeuXJnF+J0VBgwYkMW88cYbhfaqVauymKjPHzsqvPALDixbtiyL8Uno4447Los55phjsr6jjz660J48eXIWg/bhF7GI+OKHKgtdNCrafQZdjx9P0ZiLrpFf+tKXCu3hw4dnMV/84hcL7ah4rUrBTVQA2YghQ4ZkfQ899FChvXjx4o06Ju8kAQAowSQJAEAJJkkAAEowSQIAUKLDFO585CMfyfqiwgNfBBMVOfiinBUrVmQx/nHdunXLYnr06JH1+VV41qxZk8X4YqIoKe1XnYiKe6Ik9B133FFo77///lkM2sfMmTNbjPE/92ilkSqrplTZEWH16tUtHgednx9jUSHNsccem/XttttuhXZ0HbvhhhsKbV8kI0nf+c53Cu0FCxZkMf3798/6fAHkZz7zmSxm8ODBhfaOO+6YxVx99dWF9sbuVMI7SQAASjBJAgBQgkkSAIAS7ZaT3H333QvtPffcM4uJcok+dxjt/u7zNdEuIF70eXuUG/Kf70e5IX+OUYzPm0Y50aVLl7Z47CgnW+XmXbS++fPnF9rR+KmSk4zGa5VdP3yuxS+8gc4vGidVrn/vfe97sz4/nqKFW0aNGlVoR4vCvP/97y+0o0VaevfunfX5341Zs2ZlMf6cotf68MMPZ30bg3eSAACUYJIEAKAEkyQAACWYJAEAKNFuhTt+N4tIdNOnL1yJErW+cKVKUU5UZNHo6vV+gYGouMj3RQUcURLe32D7zne+M4uZOHFifLLYrPwuCVVu+G9094NovPqFLgYOHNjQsbHliq41/ho5cuTILMYX4Ej5jh5ViiTnzp3b4jn5cSrlhYxR38KFC7OYHXbYocXn39hdPzzeSQIAUIJJEgCAEkySAACUaLecpM+lVd2h3X8GHt2E72OiRcir5CSjz8n95+tV8qbRsX0uKlpMvcrN4Mcff3zWR06yfZx++uktxjSak/S/H9GY8n3Rjd0PPPBApedD53XmmWdmfVHezm+6EG244BcBiI7jc5DRmI+uf/76G10Pe/XqVWivXbs2i9lUvJMEAKAEkyQAACWYJAEAKMEkCQBAiXYr3PG7fkTJ3Kgox/ctWbKkxZjo2L4vupk/epwv1Ili/LGiAqAqu4VXKSbab7/9shi0D1+4E+124IvRonEX/dy96HG+QO2MM87IYs4///wWj40thx8H0eIqvrgm2nFp5syZWZ9fjGLo0KFZTJUCyKi40YsWGPDXxCoLJUS7iWwq3kkCAFCCSRIAgBJMkgAAlGi3nKT/vDu6CXT77bfP+vxNp1FO0C8mEOUEfW5ou+22y2Kix/ljR5+l+8/l/SK8Un4TbL9+/Vo8jpS/3gMOOCCLweYX5XVWrFhRaFcZd1Xyj5FooY3Vq1cX2v37989idtxxx0J73rx5DT0/YlUWtW9U1boJzy8q0b179ywmGk8+rk+fPlmMz4NXWeSiyiIxUl5vUmWB9V122SWL8TUqG7vgAO8kAQAowSQJAEAJJkkAAEowSQIAUKLdCnd8UcHUqVOzmCgp7YshoptnfaI2ulHfi44TPc73RTH+5tkomb106dJCO0rKR8ls/3zRyvzY/I455piszxc6RLvP+OKD1irqkPKxERUOnXzyyYX2dddd12rPj9b9eTZScBKNy5NOOqnQjs6xb9++WV+VXYj8GIuKa6osoOGLzqR8F5KoSNI/f7S4zL777lto/+1vf8timsM7SQAASjBJAgBQgkkSAIASTJIAAJRok8KdnXbaKevzq7VHRTrRKjg+eRslav1KPdFxfKFO9PxVduaIkuA+MR3F+GR2VGQRnffChQsL7d122y2L2X333QvtKVOmZDHYNPvss0/WFxUkeFXGT1SwVSWmyuN8EQOqi76/TBYQjQAACHJJREFU/ve4ys8liol+/6sU6pxzzjmF9kEHHZTFXHLJJYX2WWedlcXsvPPOWZ9fFSzalckX10Sr6VRZcScqEvIrWEXP77+X0e/g4YcfXmhTuAMAQCthkgQAoASTJAAAJdokJ+lzZFKe74t2cY92xvA7akQ3mPobU6Pcos9JRp+TR30tHafqsavcVF5lJ+7otfmdQchJtr5Bgwa1GNNovrGKKrstRDntqD4A1VTZlac1jRkzptC+4IILshi/K9LFF1+cxRx77LGFdrQr0eTJk7O+gw8+uNCOXqu/tkU7N/k8YZRbXLlyZdbnF+eokqONznHXXXdt8XHN4Z0kAAAlmCQBACjBJAkAQAkmSQAASrRJ4c7AgQPzJ3ZFKT179sxi/M2sUl6MEBVQ+OKIKOHuC4WiAphooQJ/LJ9clvIdTqokvKMiiyjB7fuioqDoWGhdUVGVV6UYLBqbVXatqfp8XlS0gcbtvffehXZ0HfPXg/322y+L2WOPPVp83MSJE7OY73znO4W2L7aR8p1BFi9enMUMGDAg61u0aFGhHRVJ+t1DqiyKEI3TqCjHFwFFCwX4nXaiwrjotW0M3kkCAFCCSRIAgBJMkgAAlGiTnOTgwYOzPr94rW9L8aK3PpcY3czv80XR59Q+bxd9Th7tLO9zkNHz+3OMcoRVFrqOzsk/f5S/ivIiaF1RfsZbv359Q8dudPFy/3xRLry1FjPoivxC4VJ887xXZeGUhx56KOubM2dOoe0XE5ek8ePHF9rHHXdcFuMfF+UNfW41El2j/cItEX89jnKL0Tn5hRKq5NyjMb+peXjeSQIAUIJJEgCAEkySAACUYJIEAKBEmxTuRKuw+yKDKklZKU8CR4Uz/sbUqIDCJ9Oj40RFDn61+ior00eJap9gjpLLUeGQT8JHNwYPHz68xXPCpol206hy03QV0Xj1hUJVioKiGBaaqO5DH/pQoT169Ogs5uWXXy60owIc/zsaFdtFv7NDhw4ttI844ogsxhdFRguw+AKYqOgsKkDy5xmNJ389iq6j/voXXQ+ja60v5omO7RdXiY4dFTxtDN5JAgBQgkkSAIASTJIAAJRok5ykXwRXyj8njj7vjnI6/qb76CbUKsep8rjoc3r/uCjH419L9FxVckNVFhiIvm/R9xutK8p9+J9NlZhIlZ97leNEi7CTk4z5m/Il6fTTTy+0o9+1Qw89tNA+/PDDsxifS4vy2RFf/xA9v1+YIBo7fhxGMdHCLVX07t270I4WMvF90RiskpOsUlsSjXmf7x0xYkQW0xzeSQIAUIJJEgCAEkySAACUYJIEAKBEmxTuRAUMvs/vbiHFBSj+hu0qO3xUWXU+ulE1uunXJ72jx/kEc5SorrLCfZRg9683WvWe4ozNL/p5+fFSZTePaIxFx65SuOPHXdVjo1pRSJ8+fbIYfz2Kfmd9Mcn8+fOzmOhxVWL8eIqudf51RMU1AwYMyPr8ogPReB4zZkyhPXv27Cxm5syZhfbChQuzmOjY/ryr7LwTXQ/9azvooINaPE5T/MYAAFCCSRIAgBJMkgAAlGCSBACgRJsU7vgiFSlPsEaJ2ygJ7YtSohUWogS751fLf/3117OY1atXZ31+1fnotXnRyj2+UCB6/dHOIL7AKXr9UWEAWldUHOWLuKJCC99Xddw38riocCcaU5AeeeSRrO/4448vtE899dQs5sQTTyy099577yzGX1uin0FUlOJ/5tFKPX4c+iIZSRo1alShvWDBgixm4sSJWZ/f4WTSpElZzCuvvFJov/baa1nMtGnTCu0lS5ZkMdE121/r/LVXkmbNmlVoVymAiopEm8M7SQAASjBJAgBQgkkSAIASbZKTjHIjPn8T5fbmzZuX9UX5PS/6zL2l548+y47yBD6XumbNmhafK1ph37/e6HX5Ff6l/GbwKG86ZMiQFs8JmybKG/rxEo37KgsORI/zcdF49WOzyo4QqO62226r1OcNGjSo0I5u3I9ycv4a4esopHynkBUrVmQxvm4hyj9uTp/97GcL7V122SWL8blNKb9uRt83v5tUdK1dvHhxof3cc89lMbfeemvWtwHvJAEAKMEkCQBACSZJAABKMEkCAFCiTQp3quw8sOOOO2Z9v/zlL7O+/v37F9pHHnlkFuNXmY9Whvc380e7AEQ36lcpjvBFFtHr9zcURwsARDfP+sdFhUO+UACtr1+/flmf/3lFBThVbmSusntHFON3tomKwSjcaXu+kLBKYWFncscdd7T3KWwS3kkCAFCCSRIAgBJMkgAAlGiTnGS0GLTPpUV5u+hm/tGjRxfa/mZaKb+hNMpJVskbRjd6+2NVuWE8WhTA3xgcLQAQLRbsRTlRn5tC64sWuvCLZE+dOjWL8Tn1KEc5dOjQrK9KLnzt2rWF9m677ZbFRLl3AOV4JwkAQAkmSQAASjBJAgBQgkkSAIASbVK4M3jw4Kxvn332KbSjm5yjleF94cOwYcOyGH8zvS9okPLV8qPinmjVfV/ME513VPDj9e3bt9B+9NFHs5jo2GPGjCm0o1Xvo50A0LpGjBiR9b3wwguFdrQYhC+cmTt3bhYTLQLgi8GmT5+exTz77LOF9rXXXpvFRMVEAMrxThIAgBJMkgAAlGCSBACgRJvkJK+66qqs76WXXmrxcZdccknW5xch+Pd///cWY3r37p3F+LyP3wVcivOU/iZyvzO2lC9wEN14vmjRokL79ttvz2IOPvjgrO+iiy4qtKPFDO68886sD63L77Yu5fniaIz7hfyjhdKfeeaZrM+P4RkzZmQxfgf2aLf12bNnZ30AyvFOEgCAEkySAACUYJIEAKAEkyQAACUs2k0AAADwThIAgFJMkgAAlGCSBACgBJMkAAAlmCQBACjBJAkAQIn/D4eJO/zDDYCGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 8\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.1394, -0.3152,  0.4595,  0.4251, -0.1407, -0.3301,  0.2539, -0.1120,\n",
      "          0.0573, -0.0136, -0.1693, -0.0910, -0.7130, -0.2595,  0.4910,  0.1078,\n",
      "         -0.1511,  0.5053, -0.6636,  0.1522],\n",
      "        [-0.0575, -0.2614,  0.2191,  0.2988,  0.0317, -0.0749,  0.1248,  0.2029,\n",
      "          0.3869,  0.2987, -0.4733,  0.1524, -0.2426,  0.3328,  0.2625,  0.4526,\n",
      "         -0.2879,  0.5362, -0.1984,  0.1088],\n",
      "        [-0.1206, -0.0424,  0.4086,  0.3124,  0.0132, -0.1855,  0.2120, -0.0960,\n",
      "          0.2567,  0.2175, -0.6446, -0.0221, -0.6177, -0.0667,  0.2415,  0.2800,\n",
      "          0.0085,  0.5341, -0.6475,  0.2914]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.4595, 0.4251, 0.0000, 0.0000, 0.2539, 0.0000, 0.0573,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4910, 0.1078, 0.0000, 0.5053,\n",
      "         0.0000, 0.1522],\n",
      "        [0.0000, 0.0000, 0.2191, 0.2988, 0.0317, 0.0000, 0.1248, 0.2029, 0.3869,\n",
      "         0.2987, 0.0000, 0.1524, 0.0000, 0.3328, 0.2625, 0.4526, 0.0000, 0.5362,\n",
      "         0.0000, 0.1088],\n",
      "        [0.0000, 0.0000, 0.4086, 0.3124, 0.0132, 0.0000, 0.2120, 0.0000, 0.2567,\n",
      "         0.2175, 0.0000, 0.0000, 0.0000, 0.0000, 0.2415, 0.2800, 0.0085, 0.5341,\n",
      "         0.0000, 0.2914]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0262,  0.0192, -0.0312,  ...,  0.0333, -0.0348,  0.0244],\n",
      "        [ 0.0216,  0.0267, -0.0165,  ..., -0.0244,  0.0006,  0.0186]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0254, 0.0151], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0125,  0.0188, -0.0423,  ..., -0.0323, -0.0292,  0.0290],\n",
      "        [-0.0357,  0.0264, -0.0088,  ..., -0.0411,  0.0055, -0.0274]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0393,  0.0005], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0148,  0.0324, -0.0049,  ...,  0.0274,  0.0384, -0.0203],\n",
      "        [ 0.0365, -0.0407, -0.0312,  ...,  0.0364,  0.0405, -0.0209]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0424, -0.0057], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Diiferentiation TORCH.AUTOGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x7fc1a0771820>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7fc1a0771520>\n",
      "\n",
      "tensor([3.4820, 3.5382, 0.9681], grad_fn=<AddBackward0>) \n",
      "\n",
      " tensor(2.7897, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Gradient function for z =', z.grad_fn)\n",
    "print('Gradient function for loss =', loss.grad_fn)\n",
    "print()\n",
    "print(z, '\\n\\n', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3234, 0.3239, 0.2416],\n",
      "        [0.3234, 0.3239, 0.2416],\n",
      "        [0.3234, 0.3239, 0.2416],\n",
      "        [0.3234, 0.3239, 0.2416],\n",
      "        [0.3234, 0.3239, 0.2416]])\n",
      "tensor([0.3234, 0.3239, 0.2416])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n",
      "\n",
      "Second call\n",
      " tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.],\n",
      "        [4., 4., 4., 4., 8.]])\n",
      "\n",
      "Call after zeroing gradients\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.eye(5, requires_grad=True)\n",
    "out = (inp+1).pow(2)\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"First call\\n\", inp.grad)\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nSecond call\\n\", inp.grad)\n",
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nCall after zeroing gradients\\n\", inp.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.789060  [    0/60000]\n",
      "loss: 0.877979  [ 6400/60000]\n",
      "loss: 0.639077  [12800/60000]\n",
      "loss: 0.842321  [19200/60000]\n",
      "loss: 0.747211  [25600/60000]\n",
      "loss: 0.732945  [32000/60000]\n",
      "loss: 0.818604  [38400/60000]\n",
      "loss: 0.795941  [44800/60000]\n",
      "loss: 0.785059  [51200/60000]\n",
      "loss: 0.773083  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.759810 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.751797  [    0/60000]\n",
      "loss: 0.847196  [ 6400/60000]\n",
      "loss: 0.606417  [12800/60000]\n",
      "loss: 0.818203  [19200/60000]\n",
      "loss: 0.725704  [25600/60000]\n",
      "loss: 0.708562  [32000/60000]\n",
      "loss: 0.793600  [38400/60000]\n",
      "loss: 0.778819  [44800/60000]\n",
      "loss: 0.762368  [51200/60000]\n",
      "loss: 0.751682  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.737320 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.719441  [    0/60000]\n",
      "loss: 0.819210  [ 6400/60000]\n",
      "loss: 0.578530  [12800/60000]\n",
      "loss: 0.797843  [19200/60000]\n",
      "loss: 0.707147  [25600/60000]\n",
      "loss: 0.688511  [32000/60000]\n",
      "loss: 0.770903  [38400/60000]\n",
      "loss: 0.764028  [44800/60000]\n",
      "loss: 0.743091  [51200/60000]\n",
      "loss: 0.732367  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.717415 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.690892  [    0/60000]\n",
      "loss: 0.793493  [ 6400/60000]\n",
      "loss: 0.554263  [12800/60000]\n",
      "loss: 0.780301  [19200/60000]\n",
      "loss: 0.690880  [25600/60000]\n",
      "loss: 0.671600  [32000/60000]\n",
      "loss: 0.749834  [38400/60000]\n",
      "loss: 0.750824  [44800/60000]\n",
      "loss: 0.726296  [51200/60000]\n",
      "loss: 0.714774  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.699494 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.665537  [    0/60000]\n",
      "loss: 0.769773  [ 6400/60000]\n",
      "loss: 0.532990  [12800/60000]\n",
      "loss: 0.764802  [19200/60000]\n",
      "loss: 0.676536  [25600/60000]\n",
      "loss: 0.657152  [32000/60000]\n",
      "loss: 0.730148  [38400/60000]\n",
      "loss: 0.738879  [44800/60000]\n",
      "loss: 0.711465  [51200/60000]\n",
      "loss: 0.698536  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.683168 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16()\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
